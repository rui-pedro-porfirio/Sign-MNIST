# SIGN MINST Project

The SIGN MINST dataset is a collection of images of hand gestures representing numbers in sign language. It is a variation of the popular MNIST dataset, which is a collection of handwritten digits. The SIGN MINST dataset consists of 27,455 grayscale images of size 28x28 pixels, each representing a sign language gesture for a number from 0 to 24. 

The SIGN MINST dataset is a valuable resource for researchers working on computer vision and machine learning applications related to sign language recognition.

**Task**: Supervised Learning Classification

**Type of Classification**: Multi-class classification (Whereas binary classifiers distinguish between two classes, multiclass classifiers (also called multinomial classifiers) can distinguish between more than two classes)

**Models Tested**: kNN + Logistic Regression + Random Forest + MLP
